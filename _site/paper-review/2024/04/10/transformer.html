<!doctype html>
















<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="ko-KR" 
  
    data-mode="light"
  
>
  <!-- The Head -->

<head>
     
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  >

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Attention is all you need" />
<meta property="og:locale" content="ko_KR" />
<meta name="description" content="Attention Is All You Need" />
<meta property="og:description" content="Attention Is All You Need" />
<link rel="canonical" href="https://denev6.github.io/paper-review/2024/04/10/transformer.html" />
<meta property="og:url" content="https://denev6.github.io/paper-review/2024/04/10/transformer.html" />
<meta property="og:site_name" content="Jin’s Notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-04-10T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Attention is all you need" />
<meta name="twitter:site" content="@" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-02-07T08:47:57+09:00","datePublished":"2024-04-10T00:00:00+09:00","description":"Attention Is All You Need","headline":"Attention is all you need","mainEntityOfPage":{"@type":"WebPage","@id":"https://denev6.github.io/paper-review/2024/04/10/transformer.html"},"url":"https://denev6.github.io/paper-review/2024/04/10/transformer.html"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>Attention is all you need | 
Jin's Notes
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="Jin's Notes">
<meta name="application-name" content="Jin's Notes">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">
  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.2/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.21.1/dist/tocbot.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  

  <!-- A placeholder to allow defining custom metadata -->
<meta property="og:image" content="/assets/img/preview.jpg">
</head>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      TeX: {
        equationNumbers: {
          autoNumber: "AMS"
        }
      },
      tex2jax: {
      inlineMath: [ ['$', '$'] ],
      displayMath: [ ['$$', '$$'], ['\\[', '\\]'] ],
      processEscapes: true,
    }
  });
  MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
      });
  MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
      });
</script>
<script
  type="text/javascript"
  async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"
></script>


  <body>
    <!-- The Side Bar -->

<aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end">
  <header class="profile-wrapper">
    <a href="/" id="avatar" class="rounded-circle">
      
      
      <img src="/assets/img/avatar.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'">
      
    </a>

    <h1 class="site-title">
      <a href="/">Jin's Notes</a>
    </h1>
    <p class="site-subtitle fst-italic mb-0">호기심 가득한 개발자의 노트</p>
  </header>
  <!-- .profile-wrapper -->

  <nav class="flex-column flex-grow-1 w-100 ps-0">
    <ul class="nav">
      <!-- home -->
      <li class="nav-item">
        <a href="/" class="nav-link">
          <i class="fa-fw fas fa-home"></i>
          <span>홈</span>
        </a>
      </li>
      <!-- the real tabs -->
      
        <li class="nav-item">
          <a href="/about/" class="nav-link">
            <i class="fa-fw fas fa-info-circle"></i>
            

            <span>소개</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/categories/" class="nav-link">
            <i class="fa-fw fas fa-stream"></i>
            

            <span>카테고리</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/archives/" class="nav-link">
            <i class="fa-fw fas fa-archive"></i>
            

            <span>기록</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/tags/" class="nav-link">
            <i class="fa-fw fas fa-tags"></i>
            

            <span>태그</span>
          </a>
        </li>
        <!-- .nav-item -->
      
    </ul>
  </nav>

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    

    
    

    
    <a href="https://github.com/denev6
" aria-label="github"  
      target="_blank"    
      rel="noopener noreferrer" >
      <i class="fab fa-github"></i>
    </a>
    
    
    

    
    <a href="https://denev6.tistory.com/" aria-label="blog"  
      target="_blank"    
      rel="noopener noreferrer" >
      <i class="fa-solid fa-pen"></i>
    </a>
    
    
    

    
    <a href="https://www.instagram.com/color_dnv" aria-label="instagram"  
      target="_blank"    
      rel="noopener noreferrer" >
      <i class="fa-brands fa-instagram"></i>
    </a>
    
    
    

    
    <a href="/feed.xml" aria-label="rss"  
      target="_blank"    
      rel="noopener noreferrer" >
      <i class="fas fa-rss"></i>
    </a>
    
    
  </div>
  <!-- .sidebar-bottom -->
</aside>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div class="container px-xxl-5">
        <!-- The Top Bar -->

<header id="topbar-wrapper" aria-label="Top Bar">
  <div
    id="topbar"
    class="d-flex align-items-center justify-content-between px-lg-3 h-100"
  >
    <nav id="breadcrumb" aria-label="Breadcrumb">
      

      
        
          
            <span>
              <a href="/">
                홈
              </a>
            </span>

          
        
          
        
          
        
          
        
          
        
          
            
              <span>Attention is all you need</span>
            

          
        
      
    </nav>
    <!-- endof #breadcrumb -->

    <button type="button" id="sidebar-trigger" class="btn btn-link">
      <i class="fas fa-bars fa-fw"></i>
    </button>

    <div id="topbar-title">
      
글
    </div>

    <button type="button" id="search-trigger" class="btn btn-link">
      <i class="fas fa-search fa-fw"></i>
    </button>

    <search class="align-items-center ms-3 ms-lg-0">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="검색..."
      >
    </search>
    <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">취소</button>
  </div>
</header>


        <div class="row">
          <main
            aria-label="Main Content"
            class="col-12 col-lg-11 col-xl-9 px-md-4"
          >
            

<article class="px-1">
  
    
  
    <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->


<!-- images -->



  
  

  <!-- CDN URL -->
  

  <!-- Add image path -->
  

  
    
      
      
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  

  



<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  




<!-- return -->




<header>
  <h1 data-toc-skip>Attention is all you need</h1>

  <div class="post-meta text-muted">
    <!-- published date -->
    <span>
      게시
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1712674800"
  data-df="YYYY/MM/DD"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  2024/04/10
</time>

    </span>

    

    <div class="d-flex justify-content-between">
      <!-- author(s) -->
      <span>
        

        By

        <em>
          
            <a href="https://github.com/denev6">박성진</a>
          
        </em>
      </span>

      <!-- read time -->
      <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<!--
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="3876 단어"
>
  <em>21 
분</em>
읽는 시간
</span>
-->

    </div>
    <!-- .d-flex -->
  </div>
  <!-- .post-meta -->
</header>


<div class="content">
  <p><a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a></p>

<p>본 글은 “<strong><em>Attention is All You Need</em></strong>” 논문을 번역 및 분석했다. 일부 문장은 맥락에 따라 의역되었으며, 명확한 이해를 위해 부분적으로 설명을 추가했다. 주요 용어는 정확한 의미 전달을 위해 영문 그대로 작성했다. (예: recurrent, convolutional 등)</p>

<h2 id="abstract"><span class="me-2">Abstract</span><a href="#abstract" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>기존 시퀀스 모델은 encoder-decoder가 포함된 복잡한 recurrent나 convolutional 신경망을 기반으로 한다. 본 논문은 recurrence와 convolution 없이 <strong>attention mechanisms을 기반으로 하는 간단한 Transformer 구조를 제안</strong>한다. 2종류의 기계번역 문제에서 좋은 성과를 보였고, 병렬화를 통해 학습 시간을 단축했다. 본 모델은 WMT 2014 영어-독일어 번역에서 28.4 BLEU를 달성했다. WMT 2014 영어-프랑스어 번역은 41.8 BLEU로 단일 모델 SOTA를 달성했다. 8개 GPU로 3.5일을 학습했다. Transformer를 영어 문장 성분 파싱에 적용했고, 다른 문제에도 적용 가능하다는 사실을 확인했다. 학습 데이터가 큰 상황과 제한된 상황에서 모두 잘 학습되었다.</p>

<h2 id="introduction"><span class="me-2">Introduction</span><a href="#introduction" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>RNN, LSTM, GRU는 기계 번역이나 언어 모델 분야에서 준수한 성능으로 입지를 확고히 해왔다. Recurrent 모델은 $t$ 시점 hidden state인 $h_t$를 학습하기 위해 $h_{t-1}$를 사용한다. 이러한 순차적인 구조는 병렬 연산을 활용할 수 없어 긴 시퀀스에 치명적이다. 최근 factorization tricks나 conditional computation을 이용해 연산 효율과 앞서 말한 문제를 개선했다. 하지만 여전히 모델 구조에 따른 근본적인 제약이 있다.</p>

<p>Attention mechanisms는 시퀀스 길이에 관계없이 의존성 모델링이 가능하며, 다양한 문제에서 좋은 모습을 보여준다. 하지만 대부분 Attention은 recurrent 구조와 함께 사용된다. 본 논문은 Transformer를 제안하고, recurrence를 피하는 대신 <strong>완전히 attention 구조에 의존하는 방식</strong>으로 입출력 사이 global dependency를 도출한다. Transformer는 병렬 처리를 통해 변역 문제에서 SOTA를 달성했고, 8개의 P100 GPU로 12시간을 학습했다.</p>

<h2 id="model-architecture"><span class="me-2">Model Architecture</span><a href="#model-architecture" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p><a href="/assets/posts/transformer/fig1.png" class="popup img-link "><img data-src="/assets/posts/transformer/fig1.png" alt="overall architecture" class="lazyload" data-proofer-ignore></a>
<em>fig1</em></p>

<p>*그림에서 좌측이 Encoder, 우측이 Decoder 구조다.</p>

<h3 id="encoder-decoder-stacks"><span class="me-2">Encoder-Decoder stacks</span><a href="#encoder-decoder-stacks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p><strong>Encoder</strong>는 N=6개의 동일한 층이 연결된 모습이다. 각 층은 multi-head self-attention과 간단한 position-wise fully connected feed-forward network로 구성된다. 각 sub-layer에 대해 residual connection을 적용하고, 뒤이어 정규화를 진행한다. * 그림에서  residual connection은 multi-head attention 입력을 출력과 합치는 부분을 말한다. (Add)</p>

<p>$Norm(x+Sublayer(x))$</p>

<p>residual connection을 쉽게 처리하기 위해 embedding을 포함한 모든 출력은 $d_{model}=512$ 차원으로 고정한다.</p>

<p><strong>Decoder</strong>도 N=6개의 동일한 층으로 구성된다. 내부는 Encoder에 한 개 sub-layer을 추가한 형태로, 총 3개 층으로 구성된다. 추가된 층은 Encoder 출력을 받아 multi-head attention을 수행한다. Decoder도 Encoder와 마찬가지로 residual connection과 정규화를 적용한다. 또한 첫 self-attention에 masking을 적용해 output embedding을 상쇄한다. 이를 통해 i번째 위치의 값은 i 이전 값에만 영향을 받도록 한다. *masking에 대해 다음 챕터(Applications of Attention in our Model)에서 자세히 설명한다.</p>

<h3 id="attention"><span class="me-2">Attention</span><a href="#attention" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p><a href="/assets/posts/transformer/fig2.png" class="popup img-link "><img data-src="/assets/posts/transformer/fig2.png" alt="attention 종류" class="lazyload" data-proofer-ignore></a>
<em>fig2</em></p>

<h4 id="scaled-dot-product-attention"><span class="me-2">Scaled Dot-Product Attention</span><a href="#scaled-dot-product-attention" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>입력은 $d_k$ 차원의 query, key와 $d_v$ 차원의 value이다. Query와 Key를 점곱한 뒤 $\sqrt{d_k}$로 나누고 softmax를 통해 각 value에 대한 가중치를 얻는다.</p>

<p>$Attention(Q,K,V)=softmax(\cfrac{QK^T}{\sqrt{d_k}})V$</p>

<p>Dot-product attention은 최적화된 행렬 연산 코드를 이용하기 때문에 다른 attetion에 비해 빠르고 공간 효율성이 좋다. 그리고 $d_k$가 큰 값이면 점곱의 결과가 커진다. 이는 softmax 연산 시 매우 작은 gradient로 이어질 수 있다. 문제를 해결하기 위해 $\cfrac{1}{\sqrt{d_k}}$로 스케일링했다.</p>

<h4 id="multi-head-attention"><span class="me-2">Multi-Head Attention</span><a href="#multi-head-attention" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>각 query, key, value에 대해 attention 연산하는 것보다 각각 $d_k,d_k,d_v$ 차원으로 h번 linearly project 하는 것이 효율적이다 (Fig2 참고). 그리고 각 query, key, value에 대해 병렬로 attention을 수행해 $d_v$ 차원의 출력을 계산한다. 이 값은 다시 concat &amp; project 되어 출력이 된다. Mutil-head attention은 다른 위치에 다른 영역에서 온 정보를 한 번에 확인할 수 있다.</p>

<p>$MultiHead(Q,K,V)=Concat(head_1,…,head_h)W^O$</p>

<p>where $head_i=Attention(QW_i^Q,KW_i^K,VW_i^V)$</p>

<p>$W_i^Q,W_i^K,W_i^V$과 $W^O\in\mathbb{R}^{hd_v\times d_{model}}$는 project 될 때 사용하는 parameter다.</p>

<p>본 연구는 h=8개의 병렬된 attention 층을 사용한다. 각 차원은 $d_k=d_v=d_{model}/h=64$이다. 줄어든 차원 덕분에 전체 연산 비용은 singe-head attention과 유사하다.</p>

<p>*여기서 차원이 줄었다는 표현은 병렬 연산을 하며 나타난 효과다. 위 설명에 따르면 $d_k=64$차원의 모델 8개를 병렬로 처리한다. 이는 $d_{model}=512$차원의 모델 하나를 처리하는 것과 같다 (512 = 64 x 8).</p>

<h4 id="applications-of-attention-in-our-model"><span class="me-2">Applications of Attention in our Model</span><a href="#applications-of-attention-in-our-model" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>Transformer는 multi-head attention을 3가지 방식으로 활용한다.</p>

<p><a href="/assets/posts/transformer/attention.png" class="popup img-link "><img data-src="/assets/posts/transformer/attention.png" alt="K, V, Q 위치" class="lazyload" data-proofer-ignore></a></p>

<p>encoder-decoder attention 층에서 query는 이전 decoder에서 오고, key와 value는 encoder 출력에서 나온다. 따라서 decoder가 모든 입력 시퀀스 위치에 적용된다. 이는 seq2seq에서 전형적인 encoder-decoder attention 구조와 동일하다.</p>

<p>encoder는 <strong>self-attention</strong> 층을 가지고 있다. self-attention에서 key, value, query는 같은 곳에서 나오며, 본 연구에서는 encoder 이전 층의 출력을 말한다. 따라서 encoder 위치가 이전 encoder의 모든 위치를 참고하게 된다. *자세히 말하면, embedding 된 단어를 key, value, query로 사용한다. 이를 통해 각 벡터 간 거리를 계산한다.</p>

<p>decoder도 마찬가지로 self-attention을 통해 모든 위치를 참조한다. 하지만 auto-regressive 속성을 유지하기 위해 다음 출력의 영향을 받으면 안 된다. 따라서 softmax 입력을 모두 <strong>masking</strong>(-∞로 설정)하는 방식을 scaled dot-production attention에 적용했다.</p>

<p>*Transformer는 순차적으로 정보를 입력하는 encoder-decoder와 달리 모든 값을 한 번에 입력한다. 따라서 미래 정보를 확인할 수 있다. 예를 들어, “the song <em>Attention</em> by <em>Newjeans</em>“라는 문장이 있다고 하자. Newjeans는 Attention 뒤에 위치한다. 따라서 시간 상 Attention → Newjeans 관계를 파악하는 것은 바람직하다. 하지만 Newjeans → Attention 순서로 맥락을 파악하는 것은 바람직하지 않은(illegal) 연결이다. 이러한 문제를 해결하기 위해 masking을 사용한다. masking 된 정보를 -∞로 설정하는 이유는 softmax를 거쳤을 때 0이 되도록 하기 위함이다.</p>

<p><a href="/assets/posts/transformer/masking.png" class="popup img-link "><img data-src="/assets/posts/transformer/masking.png" alt="masked matrix" class="lazyload" data-proofer-ignore></a></p>

<h3 id="position-wise-feed-forward-networks"><span class="me-2">Position-wise Feed-Forward Networks</span><a href="#position-wise-feed-forward-networks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>각 sub-layer는 fully connected feed-forward network를 가진다. 모두 동일한 형태로 각 위치에 적용된다. 2개의 linear 층이며 ReLU를 활성화 함수로 사용한다.</p>

<p>$FFN(x)=ReLU(xW_1+b_1)W_2+b_2$</p>

<p>선형 변환에서 각 층마다 다른 파라미터를 가진다. 입출력은 $d_{model}=512$ 차원으로 내부 층은 $d_{ff}=2048$ 차원이다. (2048 =512 x 4. W1, W2, b1, b2에 대해)</p>

<h3 id="embeddings-and-softmax"><span class="me-2">Embeddings and Softmax</span><a href="#embeddings-and-softmax" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>$d_{model}$ 차원의 벡터로 입출력을 변환하기 위해 학습된 embedding을 사용한다. decoder 출력을 확률로 변환하기 위해 선형 변환과 softmax를 사용했다. 본 연구는 두 embedding 층과 softmax 이전 선형 변환에서 같은 가중치 행렬을 사용했다. 그리고 embedding 층에서는 가중치에 $\sqrt{d_{model}}$을 곱한다.</p>

<h3 id="positional-encoding"><span class="me-2">Positional Encoding</span><a href="#positional-encoding" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>본 모델은 순환 구조가 없기 때문에 시퀀스 순서를 이해하기 위해 토큰에 위치 정보가 필요하다. 이를 위해 <strong>positional encoding</strong>을 encoder와 decoder의 input embedding 밑부분에 추가했다. positional encoding은 embedding과 더해질 수 있도록 같은 $d_{model}=512$ 차원을 가진다. 본 연구는 여러 방법 중 다른 주기를 가지는 sine과 cosine 함수를 이용한다.</p>

<p>$PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})$</p>

<p>$PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})$</p>

<p><em>pos</em>는 위치이며, <em>i</em>는 차원이다. 각 차원은 정현파(sinusoid)에 대응된다. 주기는 $2\pi$에서 $10000\cdot 2\pi$가 된다.</p>

<p><strong>positional encoding 추가 설명</strong></p>

<p><a href="/assets/posts/transformer/pos.png" class="popup img-link "><img data-src="/assets/posts/transformer/pos.png" alt="positional encoding" class="lazyload" data-proofer-ignore></a></p>

<p>말 그대로 embedding 된 단어에 위치 정보를 추가해 주는 역할이다. 위치를 표기하는 방법은 다양하다. 예를 들어 첫 번째 단어는 1 … i번째 단어는 i로 나타낼 수 있다. 그런데 i 값이 너무 커지면 더했을 때 임베딩된 벡터와 관계없이 아주 큰 값이 된다. 임베딩 벡터는 단어 정보를 담고 있기 때문에 중요하다. 따라서 항상 -1 ~ 1 사이 범위를 가지는 sine, cosine 함수를 선택했다.</p>

<p>하지만 sine, cosine은 일정한 주기를 가지기 때문에 i가 커지면 중복 값이 발생할 수 있다. 따라서 논문에서는 i마다 다른 주기를 가지도록 PE 함수를 정의했다. 물론 i 값이 매우 커지면 겹치는 경우가 발생할 수 있지만, 현재 연구에서는 i에 비해 주기가 충분히 크기 때문에 문제가 되지 않는다.</p>

<p><a href="/assets/posts/transformer/sin-cos.png" class="popup img-link "><img data-src="/assets/posts/transformer/sin-cos.png" alt="sine and cosine" class="lazyload" data-proofer-ignore></a></p>

<p>이를 통해 값이 너무 작거나 크지 않으면서 값이 중복되지 않도록 positional encoding을 수행했다.</p>

<h2 id="why-self-attention"><span class="me-2">Why Self-Attention?</span><a href="#why-self-attention" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>self-attention을 사용한 이유는 크게 3가지이다.</p>

<p>첫 번째는 <strong>연산 복잡도</strong>가 작다. 다른 하나는 연산을 <strong>병렬로 처리</strong>할 수 있다. 세 번째는 <strong>장거리 의존성</strong>(long-range dependencies)이다. 장거리 의존성을 가지는 학습에서 중요한 요인은 앞뒤로 정보를 주고받을 수 있는 경로의 거리다. 이 거리가 짧을수록 장거리 의존성을 학습하기 쉽다. 그래서 layer 종류에 따라 입력과 출력 간 경로 최대 길이를 비교했다.</p>

<p><a href="/assets/posts/transformer/table1.png" class="popup img-link "><img data-src="/assets/posts/transformer/table1.png" alt="" class="lazyload" data-proofer-ignore></a>
<em>table1</em></p>

<p>표에서 볼 수 있듯이 self-attention은 상수 시간으로 모든 위치를 연결한다. 반면 recurrent 모델은 O(n)이 걸린다. 단일 convolution에서 kernel 크기 k가 n보다 작으면 모든 입출력 위치를 연결할 수 없다. 따라서 contigious kernel에 대해 $O(n/k)$개의 convolutional 층이 필요하고, dilated convolution에 대해 $O(\log_k(n))$가 들어 오히려 최대 길이가 증가한다. convolutional 층은 k 때문에 일반적으로 recurrent 층보다 비용이 많이 든다. seperable convolutional 층은 복잡도를 $O(knd+nd^2)$으로 매우 크게 줄여주지만 k = n이더라도 self-attetion + feed-forward layer와 동일하다.</p>

<p>추가로 self-attention은 더 많은 해석 가능한(interpretable) 모델을 생산해 낼 수 있다. attention distribution을 살펴보면 아래 그림과 같다.</p>

<p><a href="/assets/posts/transformer/fig5.png" class="popup img-link "><img data-src="/assets/posts/transformer/fig5.png" alt="" class="lazyload" data-proofer-ignore></a>
<em>fig5</em></p>

<p>다양한 문제를 잘 해결할 뿐만 아니라 문장 의미와 문법을 잘 나타낸다.</p>

<h2 id="training"><span class="me-2">Training</span><a href="#training" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<h3 id="training-data-and-batching"><span class="me-2">Training Data and Batching</span><a href="#training-data-and-batching" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>450만 개 문장 쌍으로 구성된 <strong>stardard WMT 2014</strong> 영어-독일어 데이터를 학습했다. 영어-프랑스 번역 문제에서 3600만 개 WMT 영어-프랑스어 데이터를 사용했고, 토큰을 32000 word-piece 단어로 나눴다. 문장 쌍은 시퀀스 길이 정도로 batch 했다. 각 training batch는 대략 25000 source token과 25000개 target token을 담고 있는 문장 쌍이 들어있다.</p>

<h3 id="hardware-and-schedule"><span class="me-2">Hardware and Schedule</span><a href="#hardware-and-schedule" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>8개의 NVIDIA P100 GPU로 학습했다. 논문에서 설명한 base model은 각 step이 0.4초 정도로 총 100,000 step, 12시간을 학습했다. big model은 각 step 당 1.0초로 300,000 step, 3.5일을 학습했다.</p>

<h3 id="optimizer"><span class="me-2">Optimizer</span><a href="#optimizer" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p><strong>Adam</strong> optimizer를 사용했고, $\beta_1=0.9,\beta_2=0.98,\epsilon=10^{-9}$이다. 아래 수식을 이용해 learning rate를 변화해 가며 학습했다.</p>

<p>$lrate=d^{-0.5}_{model}\cdot min(step\_num^{-0.5},step\_num\cdot warmup\_steps^{-1.5})$</p>

<p><a href="/assets/posts/transformer/lr.png" class="popup img-link "><img data-src="/assets/posts/transformer/lr.png" alt="learning rate" class="lazyload" data-proofer-ignore></a></p>

<h3 id="regularization"><span class="me-2">Regularization</span><a href="#regularization" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p><strong>Residual dropout</strong>: 각 sub-layer가 입력과 더해지고 정규화되기 전에 dropout 시킨다. 추가로 embedding과 positional encoding 합에도 dropout을 적용한다. base model은 $P_{drop}=0.1$을 적용한다.</p>

<p><strong>Label smoothing</strong>: label smoothing factor로 $\epsilon_{ls}=0.1$을 사용한다. 모델을 모호하게 학습해 perplexity를 해치지만 accuracy와 BLEU 점수를 높여준다.</p>

<h2 id="result"><span class="me-2">Result</span><a href="#result" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<h3 id="machine-translation"><span class="me-2">Machine Translation</span><a href="#machine-translation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>WMT 2014 영어-독일어 번역 문제(task)에서 big transformer가 <strong>28.4 BLEU</strong>로 이전에 나온 모델을 능가하는 성능을 보였다. 모델 설정은 Table3에 기록했다. 학습은 8개 P100 GPU로 3.5일이 걸렸다. 심지어 base 모델도 학습 비용 측면에서 이전 모델 성능을 뛰어넘었다.</p>

<p>WMT 2014 영어-프랑스어 번역 문제에서 big model은 <strong>41.0 BLEU</strong>로 이전에 발표된 single model을 뛰어넘었다. 이는 이전 SOTA 모델 학습 비용의 1/4로 달성했다. 영어-프랑스어 번역에 사용한 big model은 dropout rate를 0.1 대신 0.3으로 사용했다.</p>

<p>base model은 마지막 5개 체크 포인트의 평균으로 구했으며, 각 체크 포인트는 10분 간격으로 나왔다. big model은 마지막 20개 체크 포인트를 평균 내 사용했다. beam search를 사용했고 beam size는 4, length penalty $\alpha$는 0.6이다. 하이퍼파라미터는 validation set을 통해 나온 결과로 결정했다. inference에서 최대 출력 길이를 입력 길이 + 50으로 뒀지만, 가능한 빨리 끝내는 게 좋다.</p>

<p><a href="/assets/posts/transformer/table2.png" class="popup img-link "><img data-src="/assets/posts/transformer/table2.png" alt="" class="lazyload" data-proofer-ignore></a>
<em>table2</em></p>

<p>위 표는 결과를 요약하며 번역 성능과 학습 비용을 비교한다. 학습 시간, 사용한 GPU 개수, GPU의 single-precision floating-point 성능을 고려해 floating point operations를 예측했다.</p>

<h3 id="model-variations"><span class="me-2">Model Variations</span><a href="#model-variations" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>Transformer의 component 별 중요도를 평가하기 위해 base model을 다양하게 변형해 영어-독일어 번역 성능을 측정했다. 앞서 설명했듯 beam search를 사용했고, 대신 체크포인트를 평균 내는 방식은 사용하지 않았다. 결과는 아래 표에서 볼 수 있다.</p>

<p><a href="/assets/posts/transformer/table3.png" class="popup img-link "><img data-src="/assets/posts/transformer/table3.png" alt="" class="lazyload" data-proofer-ignore></a>
<em>table3</em></p>

<p>Table3 (A) 열에서 attention head 개수, key-value 차원을 다르게 하되 연산 일관성을 유지했다. single-head attention은 0.9 BLEU로 성능이 하락했고, 너무 많은 head는 성능을 떨어뜨린다.</p>

<p>Table3 (B) 열에서 attention key 차원을 줄이니 성능에 문제가 발생했다. (C)와 (D) 열은 큰 모델일수록 성능이 좋고, dropout이 over-fitting을 막는데 도움이 된다는 사실을 보여준다. (E) 열은 sinusiudal positional encoding 대신 학습된 positional embeddings을 사용했고 base model과 거의 비슷한 결과를 보였다.</p>

<h2 id="conclusion"><span class="me-2">Conclusion</span><a href="#conclusion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Transformer는 오직 attention만을 사용한 첫 sequence transduction model이며, 가장 흔하게 사용되는 recurrent 층을 multi-headed self-attention으로 대체했다. 변역 문제에서 recurrent나 convolutional 모델에 비해 훨씬 빠르게 학습한다. WMT 2014 영어-독일어와 영어-프랑스어 문제에서 SOTA를 달성했다.</p>

<p>학습과 평가에 사용한 코드는 <a href="https://github.com/tensorflow/tensor2tensor">https://github.com/tensorflow/tensor2tensor</a>에서 확인할 수 있다.</p>

</div>


<div class="post-tail-wrapper text-muted">

  <!-- categories -->
  
    <div class="post-meta mb-3">
      <i class="far fa-folder-open fa-fw me-1"></i>
      
        <a href="/categories/paper-review/">Paper-Review</a>
    </div>
  

  <!-- tags -->
  
  <div class="post-tags">
    <i class="fa fa-tags fa-fw me-1"></i>
    
    <a href="/tags/nlp/" class="post-tag no-text-decoration">NLP</a>
    
    <a href="/tags/ai/" class="post-tag no-text-decoration">AI</a>
    
  </div>
  

  <div class="post-tail-bottom
    d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
    <div class="license-wrapper">
      
        

        이 글은 저작권자의 
        <a href="https://creativecommons.org/licenses/by-nc/4.0/">
          CC BY-NC 4.0
        </a>
         라이센스를 따릅니다.
      
    </div>

    <!-- Post sharing snippet -->

<div class="share-wrapper d-flex align-items-center">
  <span class="share-label text-muted me-1">공유하기</span>
  <span class="share-icons">
    
    
    

    
      
      <a
        href="https://twitter.com/intent/tweet?text=Attention%20is%20all%20you%20need%20-%20Jin's%20Notes&url=https%3A%2F%2Fdenev6.github.io%2Fpaper-review%2F2024%2F04%2F10%2Ftransformer.html"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Twitter"
        target="_blank"
        rel="noopener"
        aria-label="Twitter"
      >
        <i class="fa-fw fa-brands fa-square-x-twitter"></i>
      </a>
    
      
      <a
        href="https://www.facebook.com/sharer/sharer.php?title=Attention%20is%20all%20you%20need%20-%20Jin's%20Notes&u=https%3A%2F%2Fdenev6.github.io%2Fpaper-review%2F2024%2F04%2F10%2Ftransformer.html"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Facebook"
        target="_blank"
        rel="noopener"
        aria-label="Facebook"
      >
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    
      
      <a
        href="https://t.me/share/url?url=https%3A%2F%2Fdenev6.github.io%2Fpaper-review%2F2024%2F04%2F10%2Ftransformer.html&text=Attention%20is%20all%20you%20need%20-%20Jin's%20Notes"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Telegram"
        target="_blank"
        rel="noopener"
        aria-label="Telegram"
      >
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    
      
      <a
        href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fdenev6.github.io%2Fpaper-review%2F2024%2F04%2F10%2Ftransformer.html"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Linkedin"
        target="_blank"
        rel="noopener"
        aria-label="Linkedin"
      >
        <i class="fa-fw fab fa-linkedin"></i>
      </a>
    

    <button
      id="copy-link"
      aria-label="Copy link"
      class="btn small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="링크 복사하기"
      data-title-succeed="링크가 복사되었습니다!"
    >
      <i class="fa-fw fas fa-link pe-none"></i>
    </button>
  </span>
</div>

  </div>
  <!-- .post-tail-bottom -->
</div>
<!-- div.post-tail-wrapper -->


  

  
</article>

          </main>

          <!-- panel -->
          <aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted">
            <div class="access">
              <!-- Get the last 5 posts from lastmod list. -->














  <section id="access-lastmod">
    <h2 class="panel-heading">최근 수정</h2>
    <ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/playground/2025/01/17/ml-api.html">FastAPI 기반 딥러닝 모델 API 구축하기</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/paper-review/2025/02/04/resnet.html">Deep Residual Learning for Image Recognition</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/paper-review/2023/02/06/multimodal-depression.html">영상을 통한 우울증 예측 모델 분석</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/paper-review/2024/04/10/transformer.html">Attention is all you need</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/computer-vision/2025/01/29/vae.html">Auto-Encoding Variational Bayes</a>
        </li>
      
    </ul>
  </section>
  <!-- #access-lastmod -->


              <!-- The trending tags list -->















  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">인기 태그</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/ai/">AI</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">Python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/cv/">CV</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/pytorch/">Pytorch</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/c/">C++</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/nlp/">NLP</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/go/">Go</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/blog/">blog</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/mlops/">MLOps</a>
      
    </div>
  </section>


            </div>

            
              
              



  <section id="toc-wrapper" class="ps-0 pe-4 mb-5">
    <h2 class="panel-heading ps-3 pt-2 mb-2">바로가기</h2>
    <nav id="toc"></nav>
  </section>


            
          </aside>
        </div>

        <div class="row">
          <!-- tail -->
          <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              
                
                <!-- Recommend the other 3 posts according to the tags and categories of the current post. -->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->














  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
    
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  











  <aside id="related-posts" aria-labelledby="related-label">
    <h3 class="mb-4" id="related-label">관련된 글</h3>
    <nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        <article class="col">
          <a href="/projects/2022/12/17/dacon.html" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
    class="small"
  
  data-ts="1671202800"
  data-df="YYYY/MM/DD"
  
>
  2022/12/17
</time>

              <h4 class="pt-0 my-2">월간 DACON 발화자의 감정 인식 AI</h4>
              <div class="text-muted small">
                <p>
                  





                  
  대회: 월간 데이콘 발화자의 감정인식 AI 경진대회
제출 코드: dacon.io/codeshare
인터뷰: 우승자 인터뷰: 219




동기

자연어처리 대회를 소개받아 DACON 대회에 참가하게 되었다. 자연어처리 과목을 수강하고 있었는데 교수님께서 대회를 소개해주셨다. 당시 멀티모달 우울증 탐지 연구를 하고 있었기 때문에 감정 분석 모델에 ...
                </p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/projects/2025/03/24/retrieve-notice.html" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
    class="small"
  
  data-ts="1742742000"
  data-df="YYYY/MM/DD"
  
>
  2025/03/24
</time>

              <h4 class="pt-0 my-2">RAG로 학교 공지 검색</h4>
              <div class="text-muted small">
                <p>
                  





                  프로젝트를 시작하며

Retrieval-Augmented Generation(RAG)를 이용해 학교 공지를 빠르게 찾는 챗봇을 구현했다. Encoder + FAISS + SQLite를 이용해 로컬 GPU로 실험했으며, 문장 요약을 위해 GPT-3.5-turbo를 사용했다.



Github 보기

챗봇을 만든 이유는 단순하다. 평소와 같이 강의를 듣기...
                </p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/computer-vision/2025/02/08/fcn.html" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
    class="small"
  
  data-ts="1738940400"
  data-df="YYYY/MM/DD"
  
>
  2025/02/08
</time>

              <h4 class="pt-0 my-2">Image Segmentation with FCN</h4>
              <div class="text-muted small">
                <p>
                  





                  이미지 segmentation에 대해 다루며, CNN을 활용한 FCN(Fullly Convolutional Network)을 중심으로 소개한다. FCN은 논문 “Fully Convolutional Networks for Semantic Segmentation“에서 소개되었다.

Image Segmentation



이미지 segmentation은 픽...
                </p>
              </div>
            </div>
          </a>
        </article>
      
    </nav>
  </aside>
  <!-- #related-posts -->


              
                
                <!-- Navigation buttons at the bottom of the post. -->

<nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation">
  
  

  
    <a
      href="/playground/2023/10/15/init-chripy.html"
      class="btn btn-outline-primary"
      aria-label="이전 글"
    >
      <p>Chripy 블로그 만들기</p>
    </a>
  

  
    <a
      href="/computer-vision/2025/01/03/transformation.html"
      class="btn btn-outline-primary"
      aria-label="다음 글"
    >
      <p>이미지 변환 행렬과 OpenCV</p>
    </a>
  
</nav>

              
                
                <!--  The comments switcher -->

  
  <!-- https://utteranc.es/ -->
<script src="https://utteranc.es/client.js"
        repo="denev6/utterances"
        issue-term="pathname"
        crossorigin="anonymous"
        async>
</script>

<script type="text/javascript">
  $(function() {
    const origin = "https://utteranc.es";
    const iframe = "iframe.utterances-frame";
    const lightTheme = "github-light";
    const darkTheme = "github-dark";
    let initTheme = lightTheme;

    if ($("html[data-mode=dark]").length > 0
        || ($("html[data-mode]").length == 0
            && window.matchMedia("(prefers-color-scheme: dark)").matches)) {
      initTheme = darkTheme;
    }

    addEventListener("message", (event) => {
      let theme;

      /* credit to <https://github.com/utterance/utterances/issues/170#issuecomment-594036347> */
      if (event.origin === origin) {
        /* page initial */
        theme = initTheme;

      } else if (event.source === window && event.data &&
            event.data.direction === ModeToggle.ID) {
        /* global theme mode changed */
        const mode = event.data.message;
        theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme);

      } else {
        return;
      }

      const message = {
        type: "set-theme",
        theme: theme
      };

      const utterances = document.querySelector(iframe).contentWindow;
      utterances.postMessage(message, origin);
    });

  });
</script>



              
            

            <!-- The Footer -->

<footer
  aria-label="Site Info"
  class="
    d-flex flex-column justify-content-center text-muted
    flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3
  "
>
  <p>
    ©
    <time>2025</time>
    <a href="https://github.com/denev6">박성진</a>.
    
      <span
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="명시되지 않는 한 이 사이트의 블로그 게시물은 작성자의 Creative Commons Attribution 4.0 International(CC BY-NC 4.0) 라이선스에 따라 사용이 허가되었습니다."
      >일부 권리 보유</span>
    
  </p>

  <p>Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme
  </p>
</footer>

          </div>
        </div>

        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-11 content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">인기 태그</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/ai/">AI</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">Python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/cv/">CV</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/pytorch/">Pytorch</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/c/">C++</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/nlp/">NLP</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/go/">Go</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/blog/">blog</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/mlops/">MLOps</a>
      
    </div>
  </section>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>

      <aside aria-label="Scroll to Top">
        <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow">
          <i class="fas fa-angle-up"></i>
        </button>
      </aside>
    </div>

    <div id="mask"></div>

    

    <!-- JavaScripts -->

    <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.7.1/dist/jquery.min.js,npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js,npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.9/dayjs.min.js,npm/dayjs@1.11.9/locale/ko.min.js,npm/dayjs@1.11.9/plugin/relativeTime.min.js,npm/dayjs@1.11.9/plugin/localizedFormat.min.js,npm/tocbot@4.21.1/dist/tocbot.min.js"></script>






<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script>
    /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */
    MathJax = {
      tex: {
        /* start/end delimiter pairs for in-line math */
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ],
        /* start/end delimiter pairs for display math */
        displayMath: [
          ['$$', '$$'],
          ['\\[', '\\]']
        ]
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script>





    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  /* Note: dependent library will be loaded in `js-selector.html` */
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('search-results'),
    json: '/assets/js/data/search.json',
    searchResultTemplate: '  <article class="px-1 px-sm-2 px-lg-4 px-xl-0">    <header>      <h2><a href="{url}">{title}</a></h2>      <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">        {categories}        {tags}      </div>    </header>    <p>{snippet}</p>  </article>',
    noResultsText: '<p class="mt-5"></p>',
    templateMiddleware: function(prop, value, template) {
      if (prop === 'categories') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
        }
      }

      if (prop === 'tags') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
        }
      }
    }
  });
</script>

  </body>
</html>
